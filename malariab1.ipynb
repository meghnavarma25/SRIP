{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghnavarma25/SRIP/blob/main/malariab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oIB5sLl6VgfH"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, MaxPool2D\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.layers import Activation, Convolution2D, Dropout, Conv2D,AveragePooling2D, BatchNormalization,Flatten,GlobalAveragePooling2D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "\n",
        "images = []\n",
        "labels  = []\n",
        "TRAIN_DIR = '/content/drive/MyDrive/images/train'\n",
        "IMG_SIZE = (240,240) # Image resolution\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_qSzUshVmSx",
        "outputId": "6a7be099-c09b-46d1-b1be-d25bca151b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRyX8d2GVrcK",
        "outputId": "421f61b2-cd9a-405b-9dd5-e1fbc4bcfe1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of infected images: 13780\n",
            "Number of uninfected images: 13780\n"
          ]
        }
      ],
      "source": [
        "\n",
        "infected_dir = '/content/drive/MyDrive/images/cell_images/Parasitized'\n",
        "uninfected_dir = '/content/drive/MyDrive/images/cell_images/Uninfected'\n",
        "\n",
        "\n",
        "num_infected_images = len(os.listdir(infected_dir))\n",
        "num_uninfected_images = len(os.listdir(uninfected_dir))\n",
        "\n",
        "print(f\"Number of infected images: {num_infected_images}\")\n",
        "print(f\"Number of uninfected images: {num_uninfected_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JjTymPPLilAI"
      },
      "outputs": [],
      "source": [
        "dataset_path=os.listdir('/content/drive/MyDrive/images/cell_images')\n",
        "class_labels=[]\n",
        "for item in dataset_path:\n",
        "  all_classes=os.listdir('/content/drive/MyDrive/images/cell_images'+'/'+item)\n",
        "  for room in all_classes:\n",
        "    class_labels.append((item,str('dataset_path'+'/'+item)+'/'+room))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xh5_Vu2jnPk",
        "outputId": "805901c5-2911-40e3-ee80-c49ebfd9c7fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Labels                                              image\n",
            "0  Parasitized  dataset_path/Parasitized/C52P13thinF_IMG_20150...\n",
            "1  Parasitized  dataset_path/Parasitized/C174P135NThinF_IMG_20...\n",
            "2  Parasitized  dataset_path/Parasitized/C189P150ThinF_IMG_201...\n",
            "3  Parasitized  dataset_path/Parasitized/C51AP12thinF_IMG_2015...\n",
            "4  Parasitized  dataset_path/Parasitized/C184P145ThinF_IMG_201...\n",
            "           Labels                                              image\n",
            "22043  Uninfected  dataset_path/Uninfected/C12NThinF_IMG_20150614...\n",
            "22044  Uninfected  dataset_path/Uninfected/C235ThinF_IMG_20151112...\n",
            "22045  Uninfected  dataset_path/Uninfected/C163P124ThinF_IMG_2015...\n",
            "22046  Uninfected  dataset_path/Uninfected/C72P33_ThinF_IMG_20150...\n",
            "22047  Uninfected  dataset_path/Uninfected/C85P46ThinF_IMG_201508...\n"
          ]
        }
      ],
      "source": [
        "df=pd.DataFrame(data=class_labels,columns=['Labels','image'])\n",
        "print(df.head())\n",
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIj3UH12cbEl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def copy_images(images, labels, infected_dir, uninfected_dir, dest_dir):\n",
        "    for img, label in zip(images, labels):\n",
        "        if label == 'Parasitized':\n",
        "            src_path = os.path.join(infected_dir, img)\n",
        "        else:\n",
        "            src_path = os.path.join(uninfected_dir, img)\n",
        "        dest_path = os.path.join(dest_dir, label, img)\n",
        "        shutil.copy(src_path, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNn8Ie-YXf7O",
        "outputId": "0a019f0a-9d69-4289-ddef-9a77cb339eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 22048 images\n",
            "Testing set: 5512 images\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "infected_dir = '/content/drive/MyDrive/images/cell_images/Parasitized'\n",
        "uninfected_dir = '/content/drive/MyDrive/images/cell_images/Uninfected'\n",
        "\n",
        "infected_images = os.listdir(infected_dir)\n",
        "uninfected_images = os.listdir(uninfected_dir)\n",
        "\n",
        "infected_labels = ['Parasitized'] * len(infected_images)\n",
        "uninfected_labels = ['Uninfected'] * len(uninfected_images)\n",
        "\n",
        "\n",
        "all_images = infected_images + uninfected_images\n",
        "all_labels = infected_labels + uninfected_labels\n",
        "\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/images/train'\n",
        "test_dir = '/content/drive/MyDrive/images/test'\n",
        "\n",
        "train_infected_dir = os.path.join(train_dir, 'Parasitized')\n",
        "train_uninfected_dir = os.path.join(train_dir, 'Uninfected')\n",
        "test_infected_dir = os.path.join(test_dir, 'Parasitized')\n",
        "test_uninfected_dir = os.path.join(test_dir, 'Uninfected')\n",
        "\n",
        "os.makedirs(train_infected_dir, exist_ok=True)\n",
        "os.makedirs(train_uninfected_dir, exist_ok=True)\n",
        "os.makedirs(test_infected_dir, exist_ok=True)\n",
        "os.makedirs(test_uninfected_dir, exist_ok=True)\n",
        "\n",
        "#copy_images(train_images, train_labels, infected_dir, uninfected_dir, train_dir)\n",
        "#copy_images(test_images, test_labels, infected_dir, uninfected_dir, test_dir)\n",
        "\n",
        "print(f\"Training set: {len(train_images)} images\")\n",
        "print(f\"Testing set: {len(test_images)} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va9AxJAIeIRA",
        "outputId": "befeb508-cef6-4503-b020-694d5435ca71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of infected images in train: 11024\n",
            "Number of uninfected images in train: 11024\n",
            "Number of infected images in test: 2756\n",
            "Number of uninfected images in test: 2756\n"
          ]
        }
      ],
      "source": [
        "train_para = '/content/drive/MyDrive/images/train/Parasitized'\n",
        "train_unpara='/content/drive/MyDrive/images/train/Uninfected'\n",
        "test_para='/content/drive/MyDrive/images/test/Parasitized'\n",
        "test_unpara='/content/drive/MyDrive/images/test/Uninfected'\n",
        "\n",
        "num_trp = len(os.listdir(train_para))\n",
        "num_trup = len(os.listdir(train_unpara))\n",
        "num_tsp=len(os.listdir(test_para))\n",
        "num_tsup=len(os.listdir(test_unpara))\n",
        "\n",
        "print(f\"Number of infected images in train: {num_trp}\")\n",
        "print(f\"Number of uninfected images in train: {num_trup}\")\n",
        "print(f\"Number of infected images in test: {num_tsp}\")\n",
        "print(f\"Number of uninfected images in test: {num_tsup}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R55-v9EOm5v0",
        "outputId": "c50b4390-f2d8-481a-d016-cd502d158352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22047 files belonging to 2 classes.\n",
            "Using 17638 files for training.\n",
            "Found 22047 files belonging to 2 classes.\n",
            "Using 4409 files for validation.\n",
            "Number of batches in training data: 552\n",
            "Number of batches in validation data: 138\n",
            "Number of training samples: 17638\n",
            "Number of validation samples: 4409\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "TRAIN_DIR = '/content/drive/MyDrive/images'\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32  # Adjust as needed\n",
        "\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    image_size=(240, 240),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        "    seed=123,\n",
        "    label_mode='categorical',\n",
        ")\n",
        "\n",
        "valid_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,  # Same split ratio\n",
        "    image_size=(240, 240),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    subset='validation',\n",
        "    seed=123,\n",
        "    label_mode='categorical',\n",
        ")\n",
        "\n",
        "print(f\"Number of batches in training data: {len(train_data)}\")\n",
        "print(f\"Number of batches in validation data: {len(valid_data)}\")\n",
        "\n",
        "num_train_samples = len(train_data.file_paths)\n",
        "num_valid_samples = len(valid_data.file_paths)\n",
        "print(f\"Number of training samples: {num_train_samples}\")\n",
        "print(f\"Number of validation samples: {num_valid_samples}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTHHIbtjVQlC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFzsPT_0Vnbi"
      },
      "outputs": [],
      "source": [
        "height = 240\n",
        "width = 240\n",
        "channels = 3\n",
        "input_shape = (height, width, channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMaRdqR-pfhA",
        "outputId": "1a0e10ee-81cb-4686-f009-4a1a3e275805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "27018416/27018416 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 240, 240, 3)       0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 240, 240, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb1 (Functional  (None, 8, 8, 1280)        6575239   \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1280)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6577801 (25.09 MB)\n",
            "Trainable params: 6515746 (24.86 MB)\n",
            "Non-trainable params: 62055 (242.41 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_shape = (240, 240, 3)\n",
        "\n",
        "# Preprocessing layers\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(240, 240),\n",
        "    layers.experimental.preprocessing.Rescaling(1/255)\n",
        "])\n",
        "\n",
        "# Data augmentation to reduce overtraining\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=input_shape),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# Load the EfficientNetB1 model\n",
        "efnb1 = EfficientNetB1(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    efnb1,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "model.build((None, 240, 240, 3))\n",
        "# Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PXaccoxV7Nq"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
        "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqQIlcx5WRcS",
        "outputId": "b08e3ad4-9f5e-4c9a-9948-65d8c89a4a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2205/2205 [==============================] - 7574s 3s/step - loss: 0.1635 - accuracy: 0.9433 - val_loss: 0.1972 - val_accuracy: 0.9989 - lr: 1.0000e-04\n",
            "Epoch 2/5\n",
            "2205/2205 [==============================] - 7528s 3s/step - loss: 0.1155 - accuracy: 0.9628 - val_loss: 0.5643 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/5\n",
            "2205/2205 [==============================] - 7531s 3s/step - loss: 0.1030 - accuracy: 0.9663 - val_loss: 0.2119 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/5\n",
            "2205/2205 [==============================] - 7598s 3s/step - loss: 0.0906 - accuracy: 0.9700 - val_loss: 0.1594 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
            "Epoch 5/5\n",
            "2205/2205 [==============================] - 7544s 3s/step - loss: 0.0837 - accuracy: 0.9705 - val_loss: 0.3411 - val_accuracy: 1.0000 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "model_history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=5,\n",
        "    callbacks=[early_stop, rlrop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvpjLiACx7vO",
        "outputId": "6dd55642-b3cd-4883-a24d-bc9461dcbff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5511 images belonging to 2 classes.\n",
            "173/173 [==============================] - 1038s 6s/step - loss: 0.8092 - accuracy: 0.4999\n",
            "Test Loss: 0.8092149496078491\n",
            "Test Accuracy: 0.49990928173065186\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(240, 240),#size for efficientnet b1\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Test Loss: {loss}')\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LvjCfQcw42N",
        "outputId": "ff3def3d-dd1b-49b5-b0c6-619e8d3ed9c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/saved models/B1_with_100%_val_acc.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qPKNzamiJir_WKkQcuQgl3DPzv81e3L4",
      "authorship_tag": "ABX9TyNUEwDMqOIvmD57brBGXefJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}